{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT Training for Convex Optimization Exercises\n",
    "\n",
    "This notebook trains a language model on 340 convex optimization proof problems using Supervised Fine-Tuning (SFT).\n",
    "\n",
    "**Dataset**: Boyd & Vandenberghe's \"Convex Optimization\" exercises (`exercises.jsonl`)\n",
    "\n",
    "**Approach**: \n",
    "- Train directly on optimization exercises (proof-based problems)\n",
    "- Use reasoning tags: `<start_working_out>...<end_working_out><SOLUTION>...</SOLUTION>`\n",
    "- Multiple epochs for small dataset\n",
    "- Based on Unsloth's Qwen GRPO notebook structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/grpo-tests/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 12-02 19:31:08 [vllm_utils.py:700] Unsloth: Patching vLLM v1 graph capture\n",
      "==((====))==  Unsloth 2025.11.3: Fast Qwen2 patching. Transformers: 4.57.1. vLLM: 0.11.2.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 8. Max memory: 39.494 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/Qwen2.5-1.5B with actual GPU utilization = 88.97%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.49 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 320.\n",
      "Unsloth: vLLM's KV Cache can use up to 32.19 GB. Also swap space = 6 GB.\n",
      "Unsloth: FAILED getting compilation_config with error = cannot import name 'CompilationLevel' from 'vllm.config' (/home/ec2-user/grpo-tests/.venv/lib/python3.12/site-packages/vllm/config/__init__.py)\n",
      "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
      "INFO 12-02 19:31:12 [utils.py:253] non-default args: {'dtype': torch.bfloat16, 'seed': 0, 'max_model_len': 2048, 'enable_prefix_caching': True, 'swap_space': 6, 'gpu_memory_utilization': 0.8896558598712334, 'max_num_batched_tokens': 2048, 'max_num_seqs': 320, 'max_logprobs': 0, 'disable_log_stats': True, 'enable_lora': True, 'max_lora_rank': 32, 'enable_chunked_prefill': True, 'compilation_config': {'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': None, 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': None, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': None, 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'local_cache_dir': None}, 'model': 'unsloth/Qwen2.5-1.5B'}\n",
      "INFO 12-02 19:31:19 [model.py:631] Resolved architecture: Qwen2ForCausalLM\n",
      "INFO 12-02 19:31:19 [model.py:1745] Using max model len 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 19:31:19,526\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 19:31:19 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "INFO 12-02 19:31:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='unsloth/Qwen2.5-1.5B', speculative_config=None, tokenizer='unsloth/Qwen2.5-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen2.5-1.5B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}\n",
      "INFO 12-02 19:31:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.31.23.179:38513 backend=nccl\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "INFO 12-02 19:31:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 12-02 19:31:22 [topk_topp_sampler.py:36] Using FlashInfer for top-p & top-k sampling.\n",
      "INFO 12-02 19:31:22 [gpu_model_runner.py:3259] Starting to load model unsloth/Qwen2.5-1.5B...\n",
      "INFO 12-02 19:31:22 [cuda.py:377] Using AttentionBackendEnum.FLASHINFER backend.\n",
      "INFO 12-02 19:31:26 [weight_utils.py:441] Time spent downloading weights for unsloth/Qwen2.5-1.5B: 3.110313 seconds\n",
      "INFO 12-02 19:31:26 [weight_utils.py:481] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.85it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 19:31:26 [default_loader.py:314] Loading weights took 0.60 seconds\n",
      "INFO 12-02 19:31:26 [punica_selector.py:20] Using PunicaWrapperGPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 19:31:27 [gpu_model_runner.py:3338] Model loading took 2.9550 GiB memory and 4.294009 seconds\n",
      "INFO 12-02 19:31:38 [backends.py:631] Using cache directory: /home/ec2-user/.cache/vllm/torch_compile_cache/16c7de256e/rank_0_0/backbone for vLLM's torch.compile\n",
      "INFO 12-02 19:31:38 [backends.py:647] Dynamo bytecode transform time: 9.60 s\n",
      "INFO 12-02 19:31:42 [backends.py:251] Cache the graph for dynamic shape for later use\n",
      "INFO 12-02 19:31:50 [backends.py:282] Compiling a graph for dynamic shape takes 10.85 s\n",
      "INFO 12-02 19:31:52 [monitor.py:34] torch.compile takes 20.45 s in total\n",
      "INFO 12-02 19:31:54 [gpu_worker.py:359] Available KV cache memory: 31.51 GiB\n",
      "INFO 12-02 19:31:54 [kv_cache_utils.py:1229] GPU KV cache size: 1,180,096 tokens\n",
      "INFO 12-02 19:31:54 [kv_cache_utils.py:1234] Maximum concurrency for 2,048 tokens per request: 576.22x\n",
      "INFO 12-02 19:31:55 [kernel_warmup.py:65] Warming up FlashInfer attention.\n",
      "INFO 12-02 19:31:55 [vllm_utils.py:705] Unsloth: Running patched vLLM v1 `capture_model`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-02 19:31:55 [utils.py:250] Using default LoRA kernel configs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [00:07<00:00, 13.55it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78/78 [00:05<00:00, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 19:32:08 [gpu_model_runner.py:4244] Graph capturing finished in 13 secs, took 1.37 GiB\n",
      "INFO 12-02 19:32:08 [vllm_utils.py:712] Unsloth: Patched vLLM v1 graph capture finished in 13 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 19:32:09 [core.py:250] init engine (profile, create kv cache, warmup model) took 41.89 seconds\n",
      "INFO 12-02 19:32:11 [llm.py:352] Supported tasks: ('generate',)\n",
      "Unsloth: Just some info: will skip parsing ['norm1', 'layer_norm1', 'post_feedforward_layernorm', 'q_norm', 'norm2', 'k_norm', 'attention_norm', 'post_attention_layernorm', 'post_layernorm', 'pre_feedforward_layernorm', 'layer_norm2', 'ffn_norm', 'norm', 'input_layernorm']\n",
      "Performing substitution for additional_keys=set()\n",
      "Unsloth: Just some info: will skip parsing ['norm1', 'layer_norm1', 'post_feedforward_layernorm', 'q_norm', 'norm2', 'k_norm', 'cross_attn_input_layernorm', 'attention_norm', 'post_attention_layernorm', 'post_layernorm', 'pre_feedforward_layernorm', 'layer_norm2', 'ffn_norm', 'norm', 'cross_attn_post_attention_layernorm', 'input_layernorm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.11.3 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully\n",
      "üî• CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048  # Can increase for longer proofs\n",
    "lora_rank = 32  # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-1.5B\",  # Smaller model for faster training\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False,  # False for LoRA 16bit\n",
    "    fast_inference = True,\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.9,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank * 2,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully\")\n",
    "print(f\"üî• CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Chat Template with Reasoning Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given an optimization problem.\n",
      "Think about the problem and provide your working out (proof steps).\n",
      "Place it between <start_working_out> and <end_working_out>.\n",
      "Then, provide your solution between <SOLUTION></SOLUTION>\n"
     ]
    }
   ],
   "source": [
    "reasoning_start = \"<start_working_out>\"\n",
    "reasoning_end = \"<end_working_out>\"\n",
    "solution_start = \"<SOLUTION>\"\n",
    "solution_end = \"</SOLUTION>\"\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"You are given an optimization problem.\n",
    "Think about the problem and provide your working out (proof steps).\n",
    "Place it between {reasoning_start} and {reasoning_end}.\n",
    "Then, provide your solution between {solution_start}{solution_end}\"\"\"\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chat template configured\n"
     ]
    }
   ],
   "source": [
    "# Create chat template\n",
    "chat_template = \\\n",
    "    \"{% if messages[0]['role'] == 'system' %}\"\\\n",
    "        \"{{ messages[0]['content'] + eos_token }}\"\\\n",
    "        \"{% set loop_messages = messages[1:] %}\"\\\n",
    "    \"{% else %}\"\\\n",
    "        \"{{ '{system_prompt}' + eos_token }}\"\\\n",
    "        \"{% set loop_messages = messages %}\"\\\n",
    "    \"{% endif %}\"\\\n",
    "    \"{% for message in loop_messages %}\"\\\n",
    "        \"{% if message['role'] == 'user' %}\"\\\n",
    "            \"{{ message['content'] }}\"\\\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\\\n",
    "            \"{{ message['content'] + eos_token }}\"\\\n",
    "        \"{% endif %}\"\\\n",
    "    \"{% endfor %}\"\\\n",
    "    \"{% if add_generation_prompt %}{{ '{reasoning_start}' }}\"\\\n",
    "    \"{% endif %}\"\n",
    "\n",
    "# Replace with our specific template\n",
    "chat_template = chat_template\\\n",
    "    .replace(\"'{system_prompt}'\", f\"'{system_prompt}'\")\\\n",
    "    .replace(\"'{reasoning_start}'\", f\"'{reasoning_start}'\")\n",
    "tokenizer.chat_template = chat_template\n",
    "\n",
    "print(\"‚úÖ Chat template configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Chat Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given an optimization problem.\n",
      "Think about the problem and provide your working out (proof steps).\n",
      "Place it between <start_working_out> and <end_working_out>.\n",
      "Then, provide your solution between <SOLUTION></SOLUTION><|endoftext|>Show that the intersection of convex sets is convex.<start_working_out>Let C1 and C2 be convex...<end_working_out><SOLUTION>Proven</SOLUTION><|endoftext|>What about the union?<start_working_out>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.apply_chat_template([\n",
    "    {\"role\": \"user\", \"content\": \"Show that the intersection of convex sets is convex.\"},\n",
    "    {\"role\": \"assistant\", \"content\": f\"{reasoning_start}Let C1 and C2 be convex...{reasoning_end}{solution_start}Proven{solution_end}\"},\n",
    "    {\"role\": \"user\", \"content\": \"What about the union?\"},\n",
    "], tokenize=False, add_generation_prompt=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Format Optimization Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loaded 340 optimization exercises\n",
      "\n",
      "üìã Dataset columns: ['exercise_number', 'exercise_text', 'solution_text', 'text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise_number</th>\n",
       "      <th>exercise_text</th>\n",
       "      <th>solution_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.1</td>\n",
       "      <td>Let C ‚äÜ Rn be a convex set, with x1, . . . , x...</td>\n",
       "      <td>This is readily shown by induction from the de...</td>\n",
       "      <td>2.1 Let C ‚äÜ Rn be a convex set, with x1, . . ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>Show that a set is convex if and only if its i...</td>\n",
       "      <td>We prove the Ô¨Årst part. The intersection of tw...</td>\n",
       "      <td>2.2 Show that a set is convex if and only if i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3</td>\n",
       "      <td>Midpoint convexity. A set C is midpoint convex...</td>\n",
       "      <td>We have to show that Œ∏x + (1 ‚àí Œ∏)y ‚àà C for all...</td>\n",
       "      <td>2.3 Midpoint convexity. A set C is midpoint co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.4</td>\n",
       "      <td>Show that the convex hull of a set S is the in...</td>\n",
       "      <td>Let H be the convex hull of S and let D be the...</td>\n",
       "      <td>2.4 Show that the convex hull of a set S is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>What is the distance between two parallel hype...</td>\n",
       "      <td>The distance between the two hyperplanes is |b...</td>\n",
       "      <td>2.5 What is the distance between two parallel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  exercise_number                                      exercise_text  \\\n",
       "0             2.1  Let C ‚äÜ Rn be a convex set, with x1, . . . , x...   \n",
       "1             2.2  Show that a set is convex if and only if its i...   \n",
       "2             2.3  Midpoint convexity. A set C is midpoint convex...   \n",
       "3             2.4  Show that the convex hull of a set S is the in...   \n",
       "4             2.5  What is the distance between two parallel hype...   \n",
       "\n",
       "                                       solution_text  \\\n",
       "0  This is readily shown by induction from the de...   \n",
       "1  We prove the Ô¨Årst part. The intersection of tw...   \n",
       "2  We have to show that Œ∏x + (1 ‚àí Œ∏)y ‚àà C for all...   \n",
       "3  Let H be the convex hull of S and let D be the...   \n",
       "4  The distance between the two hyperplanes is |b...   \n",
       "\n",
       "                                                text  \n",
       "0  2.1 Let C ‚äÜ Rn be a convex set, with x1, . . ....  \n",
       "1  2.2 Show that a set is convex if and only if i...  \n",
       "2  2.3 Midpoint convexity. A set C is midpoint co...  \n",
       "3  2.4 Show that the convex hull of a set S is th...  \n",
       "4  2.5 What is the distance between two parallel ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load exercises.jsonl\n",
    "exercises = []\n",
    "with open(\"exercises.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        exercises.append(json.loads(line))\n",
    "\n",
    "dataset = pd.DataFrame(exercises)\n",
    "\n",
    "print(f\"üìö Loaded {len(dataset)} optimization exercises\")\n",
    "print(f\"\\nüìã Dataset columns: {dataset.columns.tolist()}\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Sample Exercise:\n",
      "\n",
      "Number: 2.1\n",
      "\n",
      "Problem:\n",
      "Let C ‚äÜ Rn be a convex set, with x1, . . . , xk ‚àà C, and let Œ∏1, . . . , Œ∏k ‚àà R satisfy Œ∏i ‚â• 0, Œ∏1 + ¬∑ ¬∑ ¬∑ + Œ∏k = 1. Show that Œ∏1x1 + ¬∑ ¬∑ ¬∑ + Œ∏kxk ‚àà C. (The deÔ¨Ånition of convexity is that this holds f...\n",
      "\n",
      "Solution:\n",
      "This is readily shown by induction from the deÔ¨Ånition of convex set. We illus- trate the idea for k = 3, leaving the general case to the reader. Suppose that x1, x2, x3 ‚àà C, and Œ∏1 + Œ∏2 + Œ∏3 = 1 with ...\n"
     ]
    }
   ],
   "source": [
    "# Show a sample exercise\n",
    "print(\"üìù Sample Exercise:\")\n",
    "print(f\"\\nNumber: {dataset.iloc[0]['exercise_number']}\")\n",
    "print(f\"\\nProblem:\\n{dataset.iloc[0]['exercise_text'][:200]}...\")\n",
    "print(f\"\\nSolution:\\n{dataset.iloc[0]['solution_text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Dataset with Reasoning Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset formatted with reasoning tags\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(x):\n",
    "    \"\"\"Format exercise with reasoning tags.\"\"\"\n",
    "    problem = x[\"exercise_text\"]\n",
    "    solution = x[\"solution_text\"]\n",
    "    \n",
    "    # Wrap solution with reasoning tags\n",
    "    # For proofs, the entire solution text is the \"reasoning\"\n",
    "    # and we put a summary in SOLUTION tags\n",
    "    final_prompt = \\\n",
    "        reasoning_start + solution + reasoning_end + \\\n",
    "        solution_start + \"Proven.\" + solution_end\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": problem},\n",
    "        {\"role\": \"assistant\", \"content\": final_prompt},\n",
    "    ]\n",
    "\n",
    "dataset[\"Messages\"] = dataset.apply(format_dataset, axis=1)\n",
    "print(\"‚úÖ Dataset formatted with reasoning tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Formatted example (first 800 chars):\n",
      "You are given an optimization problem.\n",
      "Think about the problem and provide your working out (proof steps).\n",
      "Place it between <start_working_out> and <end_working_out>.\n",
      "Then, provide your solution between <SOLUTION></SOLUTION><|endoftext|>Let C ‚äÜ Rn be a convex set, with x1, . . . , xk ‚àà C, and let Œ∏1, . . . , Œ∏k ‚àà R satisfy Œ∏i ‚â• 0, Œ∏1 + ¬∑ ¬∑ ¬∑ + Œ∏k = 1. Show that Œ∏1x1 + ¬∑ ¬∑ ¬∑ + Œ∏kxk ‚àà C. (The deÔ¨Ånition of convexity is that this holds for k = 2; you must show it for arbitrary k.) Hint. Use induction on k.<start_working_out>This is readily shown by induction from the deÔ¨Ånition of convex set. We illus- trate the idea for k = 3, leaving the general case to the reader. Suppose that x1, x2, x3 ‚àà C, and Œ∏1 + Œ∏2 + Œ∏3 = 1 with Œ∏1, Œ∏2, Œ∏3 ‚â• 0. We will show that y = Œ∏1x1 + Œ∏2x2 + Œ∏3x3 ‚àà C. At least one\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Check formatted example\n",
    "print(\"üìÑ Formatted example (first 800 chars):\")\n",
    "print(tokenizer.apply_chat_template(dataset.iloc[0][\"Messages\"], tokenize=False)[:800])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Length\n",
    "\n",
    "Keep examples that fit within max_seq_length to avoid truncation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Length statistics:\n",
      "   Min: 108 tokens\n",
      "   Max: 2794 tokens\n",
      "   Mean: 629 tokens\n",
      "   Median: 506 tokens\n",
      "\n",
      "‚úÖ Filtered dataset:\n",
      "   Original: 340 examples\n",
      "   Kept: 336 examples\n",
      "   Removed: 4 examples (too long)\n"
     ]
    }
   ],
   "source": [
    "# Calculate token lengths\n",
    "dataset[\"N\"] = dataset[\"Messages\"].apply(\n",
    "    lambda x: len(tokenizer.apply_chat_template(x, tokenize=True))\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Length statistics:\")\n",
    "print(f\"   Min: {dataset['N'].min()} tokens\")\n",
    "print(f\"   Max: {dataset['N'].max()} tokens\")\n",
    "print(f\"   Mean: {dataset['N'].mean():.0f} tokens\")\n",
    "print(f\"   Median: {dataset['N'].median():.0f} tokens\")\n",
    "\n",
    "# Filter to examples that fit\n",
    "original_count = len(dataset)\n",
    "dataset = dataset.loc[dataset[\"N\"] <= max_seq_length].copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Filtered dataset:\")\n",
    "print(f\"   Original: {original_count} examples\")\n",
    "print(f\"   Kept: {len(dataset)} examples\")\n",
    "print(f\"   Removed: {original_count - len(dataset)} examples (too long)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset prepared for training\n",
      "   Total examples: 336\n",
      "   Columns: ['exercise_number', 'exercise_text', 'solution_text', 'text', 'Messages', 'N', '__index_level_0__']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['exercise_number', 'exercise_text', 'solution_text', 'text', 'Messages', 'N', '__index_level_0__'],\n",
       "    num_rows: 336\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply chat template to create \"text\" field\n",
    "dataset[\"text\"] = tokenizer.apply_chat_template(\n",
    "    dataset[\"Messages\"].values.tolist(), \n",
    "    tokenize=False\n",
    ")\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "print(f\"‚úÖ Dataset prepared for training\")\n",
    "print(f\"   Total examples: {len(dataset)}\")\n",
    "print(f\"   Columns: {dataset.column_names}\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure and Run SFT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Training configuration:\n",
      "   Examples: 336\n",
      "   Epochs: 15\n",
      "   Batch size: 1 x 4 = 4 (effective)\n",
      "   Steps per epoch: ~84\n",
      "   Total steps: ~1260\n",
      "   Estimated time: ~10-21 minutes on modern GPU\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Calculate training steps\n",
    "num_epochs = 15  # More epochs for small dataset\n",
    "batch_size = 1\n",
    "gradient_accumulation = 4\n",
    "steps_per_epoch = len(dataset) // (batch_size * gradient_accumulation)\n",
    "total_steps = steps_per_epoch * num_epochs\n",
    "\n",
    "print(f\"üìä Training configuration:\")\n",
    "print(f\"   Examples: {len(dataset)}\")\n",
    "print(f\"   Epochs: {num_epochs}\")\n",
    "print(f\"   Batch size: {batch_size} x {gradient_accumulation} = {batch_size * gradient_accumulation} (effective)\")\n",
    "print(f\"   Steps per epoch: ~{steps_per_epoch}\")\n",
    "print(f\"   Total steps: ~{total_steps}\")\n",
    "print(f\"   Estimated time: ~{total_steps * 0.5 / 60:.0f}-{total_steps * 1.0 / 60:.0f} minutes on modern GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=64): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 336/336 [00:10<00:00, 30.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trainer configured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 50,\n",
    "        num_train_epochs = 15,\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs/optimization_sft\",\n",
    "        save_steps = 100,\n",
    "        save_total_limit = 3,\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 336 | Num Epochs = 15 | Total steps = 1,260\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 36,929,536 of 1,580,643,840 (2.34% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n",
      "\n",
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1260/1260 23:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.605700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.379100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.197600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.081300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.984700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.867800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.826800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.860600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.869900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.643900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.555700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.623200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.609900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.695100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.421200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.432900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.220500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.253300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.122600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.068500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.078200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "trainer.train()\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Model saved to: optimization_sft_model/\n"
     ]
    }
   ],
   "source": [
    "# Save LoRA adapter\n",
    "model.save_pretrained(\"optimization_sft_model\")\n",
    "tokenizer.save_pretrained(\"optimization_sft_model\")\n",
    "\n",
    "print(\"üíæ Model saved to: optimization_sft_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inference functions ready\n"
     ]
    }
   ],
   "source": [
    "# Enable inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def generate_proof(problem: str, max_tokens: int = 1024):\n",
    "    \"\"\"Generate a proof for the given problem.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": problem}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    \n",
    "    generated = tokenizer.decode(\n",
    "        outputs[0][inputs['input_ids'].shape[1]:],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    return generated\n",
    "\n",
    "print(\"‚úÖ Inference functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: Training Example\n",
      "================================================================================\n",
      "\n",
      "üìù Problem:\n",
      "Let C ‚äÜ Rn be a convex set, with x1, . . . , xk ‚àà C, and let Œ∏1, . . . , Œ∏k ‚àà R satisfy Œ∏i ‚â• 0, Œ∏1 + ¬∑ ¬∑ ¬∑ + Œ∏k = 1. Show that Œ∏1x1 + ¬∑ ¬∑ ¬∑ + Œ∏kxk ‚àà C. (The deÔ¨Ånition of convexity is that this holds for k = 2; you must show it for arbitrary k.) Hint. Use induction on k.\n",
      "\n",
      "ü§ñ Model Generated:\n",
      "We use induction on k. The base case k = 2 follows from the deÔ¨Ånition of convex set. Suppose the result is true for k ‚àí 1, and consider the case where k is even. Without loss of generality we can assume that Œ∏ = (1, . . . , 1) T ‚àà {Œ∏}. Let x ‚àà C. We will show that y = Œ∏1x1 + ¬∑ ¬∑ ¬∑ + Œ∏kxk ‚àà C. When k = 2, this follows from the deÔ¨Ånition of convex set. Assume the result is true for k ‚àí 2, and consider the case when k is even. DeÔ¨Åne D = {Œ∏ ‚àà {Œ∏} | Œ∏ ‚™∞ 0, Œ∏ ‚â† 1}. We will show that y ‚àà cl C. Suppose y Ã∏‚àà cl C, i.e., there exists a $\\epsilon$-ball around y that does not intersect C: ![imprecisely containing ball around y](http://i.stack.imgur.com/y18VH.png) - PSfrag replacements $\\epsilon$ Ã∏= 0 with B($\\epsilon$, y) ‚à© C = ‚àÖ. Consider a point z ‚àà B($\\epsilon$, y) ‚à© C. We have ‚à•z ‚àí y‚à•2 < ‚à•z ‚àí x‚à•2 + ‚à•x ‚àí y‚à•2 ‚â§ ‚à•z ‚àí x‚à•2 + $\\epsilon$ and ‚à•z ‚àí y‚à•2 < ‚à•z ‚àí x‚à•2 + ‚à•x ‚àí y‚à•2 ‚â§ ‚à•z ‚àí x‚à•2 + $\\epsilon$, so ‚à•x ‚àí y‚à•2 < ‚à•z ‚àí x‚à•2 + ‚à•z ‚àí y‚à•2 ‚â§ ‚à•z ‚àí x‚à•2 + ‚à•x ‚àí y‚à•2 + 2$\\epsilon$. Therefore Œ∏x + (1 ‚àí Œ∏)y = (1 ‚àí Œ∏)x + Œ∏z ‚àà C, for Œ∏ = (1 ‚àí ‚à•x ‚àí y‚à•2)/(1 + ‚à•x ‚àí y‚à•2) ‚àà D. Using the induction hypothesis, z ‚àà cl C, hence y ‚àà cl C. The argument for the case k is odd is similar.<end_working_out><SOLUTION>Proven.</SOLUTION>\n",
      "\n",
      "üìä Format Check:\n",
      "   ‚úì <end_working_out>: True\n",
      "   ‚úì <SOLUTION>: True\n",
      "   ‚úì </SOLUTION>: True\n",
      "   Overall: ‚úÖ PASS\n"
     ]
    }
   ],
   "source": [
    "# Get a test problem from training set\n",
    "test_df = dataset.to_pandas()\n",
    "test_problem = test_df.iloc[0]['exercise_text']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 1: Training Example\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìù Problem:\\n{test_problem}\")\n",
    "print(f\"\\nü§ñ Model Generated:\")\n",
    "print(generate_proof(test_problem, max_tokens=1024))\n",
    "\n",
    "# Check for format tags\n",
    "generated = generate_proof(test_problem, max_tokens=1024)\n",
    "has_reasoning_end = reasoning_end in generated\n",
    "has_solution_start = solution_start in generated\n",
    "has_solution_end = solution_end in generated\n",
    "\n",
    "print(\"\\nüìä Format Check:\")\n",
    "print(f\"   ‚úì {reasoning_end}: {has_reasoning_end}\")\n",
    "print(f\"   ‚úì {solution_start}: {has_solution_start}\")\n",
    "print(f\"   ‚úì {solution_end}: {has_solution_end}\")\n",
    "print(f\"   Overall: {'‚úÖ PASS' if all([has_reasoning_end, has_solution_start, has_solution_end]) else '‚ùå FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Different Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2: Another Training Example\n",
      "================================================================================\n",
      "\n",
      "üìù Problem:\n",
      "When does one halfspace contain another? Give conditions under which {x | aT x ‚â§ b} ‚äÜ {x | ÀúaT x ‚â§ Àúb} (where a Ã∏= 0, Àúa Ã∏= 0). Also Ô¨Ånd the conditions under which the two halfspaces are equal.\n",
      "\n",
      "ü§ñ Model Generated:\n",
      "Let H = {x | aT x ‚â§ b} and Àú H = {x | ÀúaT x ‚â§ Àúb}. The conditions are: ‚Ä¢ H ‚äÜ Àú H if and only if there exists a Œª > 0 such that Àúa = Œªa and Àúb ‚â• Œªb. ‚Ä¢ H = Àú H if and only if there exists a Œª > 0 such that Àúa = Œªa and Àúb = Œªb. Let us prove the Ô¨Årst condition. The condition is clearly suÔ¨Écient: if Àúa = Œªa and Àúb ‚â• Œªb for some Œª > 0, then aT x ‚â§ b =‚áí ŒªaT x ‚â§ Œªb =‚áí ÀúaT x ‚â§ Àúb, i.e., H ‚äÜ Àú H. To prove necessity, we distinguish three cases. First suppose a and Àúa are not parallel. This means we can Ô¨Ånd a v with ÀúaT v = 0 and aT v Ã∏= 0. Let ÀÜx be any point in the intersection of H and Àú H, i.e., aT ÀÜx ‚â§ b and ÀúaT x ‚â§ Àúb. We have aT (ÀÜx + tv) = aT ÀÜx ‚â§ b for all t ‚â• 0, and ÀúaT (ÀÜx + tv) = ÀúaT ÀÜx ‚â§ Àúb for all t ‚â• 0. In particular, we can Ô¨Ånd a t such that aT (ÀÜx + tv) = ÀúaT (ÀÜx + tv) = 0, i.e., aT v = 0 = ÀúaT v, and aT (ÀÜx + tv) > b for t > 0, and ÀúaT (ÀÜx + tv) > Àúb for t > 0. This contradicts H ‚äÜ Àú H. Next suppose a and Àúa are parallel, but point in opposite directions, i.e., Àúa = Œªa for some Œª < 0. Let ÀÜx be any point in H. Then ÀÜx‚àíta ‚àà H for all t ‚â• 0, i.e., aT ÀÜx ‚àí taT a ‚â§ b for all t ‚â• 0. Since aT ÀÜx ‚àí taT a is a decreasing function of t, it has a maximum value, which occurs at t = 0. Therefore aT ÀÜx ‚àí aT a ‚â§ b for all t ‚â• 0 only if aT ÀÜx = b. This is impossible since ÀÜx ‚àà H and H is an aÔ¨Éne set. Finally, we assume Àúa = Œªa for some Œª > 0 but Àúb < Œªb. Consider any point ÀÜx that satisÔ¨Åes aT ÀÜx = b. Then ÀúaT ÀÜx = ŒªaT ÀÜx = Œªb > Àúb, so ÀÜx Ã∏‚àà Àú H. The third case cannot occur if we assume aT x ‚â§ b =‚áí ÀúaT x ‚â§ Àúb. Exercises Conversely, suppose the conditions hold. We show H = Àú H by showing H ‚äÜ Àú H and Àú H ‚äÜ H. Let ÀÜx ‚àà H. Then ÀÜx ‚àà Àú H because ÀúaT ÀÜx ‚â§ Àúb and a Ã∏= 0, Àúa Ã∏= 0. Conversely, suppose ÀÜx ‚àà Àú H. Since Àúa = Œªa for some Œª > 0, we can write ÀÜx as ÀÜx = Œªx where x ‚àà H. Dividing both sides by Œª gives ÀúaT ÀÜx = ŒªaT x ‚â§ Œªb, i.e., aT x ‚â§ b. Hence ÀÜx ‚àà H. The last condition we need to show is that H ‚äÜ Àú H if and only if the two halfspaces are equal. This follows from the fact that {x | aT x ‚â§ b} = {x | aT x = b} if a Ã∏= 0.<end_working_out><SOLUTION>Proven.</SOLUTION>\n"
     ]
    }
   ],
   "source": [
    "test_problem_2 = test_df.iloc[5]['exercise_text']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 2: Another Training Example\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìù Problem:\\n{test_problem_2}\")\n",
    "print(f\"\\nü§ñ Model Generated:\")\n",
    "print(generate_proof(test_problem_2, max_tokens=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Custom Problem (Generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 3: Custom Problem (Generalization)\n",
      "================================================================================\n",
      "\n",
      "üìù Problem:\n",
      "Show that the intersection of two convex sets is convex.\n",
      "\n",
      "ü§ñ Model Generated:\n",
      "Let S1 and S2 be convex sets. Let x, y ‚àà S1 ‚à© S2. Suppose 0 ‚â§ Œ∏ ‚â§ 1. Then Œ∏x + (1 ‚àí Œ∏)y ‚àà S1 ‚à© S2, because S1 and S2 are convex, and therefore Œ∏x + (1 ‚àí Œ∏)y ‚àà S1, Œ∏x + (1 ‚àí Œ∏)y ‚àà S2. Exercises<end_working_out><SOLUTION>Proven.</SOLUTION>\n"
     ]
    }
   ],
   "source": [
    "custom_problem = \"Show that the intersection of two convex sets is convex.\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 3: Custom Problem (Generalization)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìù Problem:\\n{custom_problem}\")\n",
    "print(f\"\\nü§ñ Model Generated:\")\n",
    "print(generate_proof(custom_problem, max_tokens=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Another Custom Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 4: Another Custom Problem\n",
      "================================================================================\n",
      "\n",
      "üìù Problem:\n",
      "Prove that a convex combination of points in a convex set remains in that set.\n",
      "\n",
      "ü§ñ Model Generated:\n",
      "Let x1, . . . , xn be a convex combination of points in the convex set C, i.e., x1 + ¬∑ ¬∑ ¬∑ + xn = 1 and xi ‚àà C for i = 1, . . . , n. Now suppose x ‚àà C. Then, for t ‚àà [0, 1], tx1 + (1 ‚àí t)x2 + ¬∑ ¬∑ ¬∑ + tnxn = tx1 + (1 ‚àí t)x2 + ¬∑ ¬∑ ¬∑ + tnxi + ¬∑ ¬∑ ¬∑ + tnxn = t(x1 + x2 + ¬∑ ¬∑ ¬∑ + xn) + (1 ‚àí t)(x2 + ¬∑ ¬∑ ¬∑ + xi + ¬∑ ¬∑ ¬∑ + xn) ‚àà C, because xi + xj ‚àà C for i Ã∏= j, and C is convex. 2 Convex sets<end_working_out><SOLUTION>Proven.</SOLUTION>\n"
     ]
    }
   ],
   "source": [
    "custom_problem_2 = \"Prove that a convex combination of points in a convex set remains in that set.\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 4: Another Custom Problem\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìù Problem:\\n{custom_problem_2}\")\n",
    "print(f\"\\nü§ñ Model Generated:\")\n",
    "print(generate_proof(custom_problem_2, max_tokens=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_question = \"\"\"\n",
    "A geothermal power plant has three geothermal wells (A, B, and C) with maximum sustainable capacities of A: 1000 units, B: 1500 units, and C: 2000 units. The maximum operating capacity of the power generation equipment is 3000 units. To maintain the pressure in the geothermal field, some of the used hot water or steam needs to be reinjected underground, with a reinjection ratio requirement of 40%. The unit extraction costs for each geothermal well are A: 5 units, B: 4 units, and C: 3 units, and the environmental protection cost is 2 units. Assuming the electricity market demand for a time period t is 2800 units, and each unit of electricity generation brings 1 unit of revenue.\n",
    "How should the extraction quantities of the three geothermal wells be scheduled to meet the electricity market demand while maximizing revenue and minimizing costs? Design a scheduling plan and calculate the maximum total revenue.\n",
    "\"\"\"\n",
    "\n",
    "random_question = \"\"\"\n",
    "Consider a polyhedron P described by linear inequality constraints:\n",
    "P= {x ‚ààRn : a‚Ä≤\n",
    "ix ‚â§bi, i = 1,...,m}. A ball with center y and radius r is defined as the\n",
    "set of all points within Euclidean distance r from y. We are interested in finding a ball with\n",
    "the largest possible radius, which is entirely contained within P. Provide a linear programming\n",
    "formulation of this problem.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpret the problem as an LP minimize 1T x subject to aT i x ‚àí yi < bi, i = 1, . . . , m, with variables x ‚àà Rn, y ‚àà Rn, and constraints on the righthand side of the inequalities. The objective is to maximize the linear function 1T x, which is easily shown to be equivalent to maximize x1. 7 Statistical estimation The constraints ensure that the ball is entirely contained in P. To show this, suppose that the ball is not contained in P. Then, there is some z ‚àà P with ‚à•z ‚àí y‚à•2 > r. Hence, 1T z > 1T y + r, and 1T z ‚àí 1T y > r, which is a contradiction. Chapter 2 Convex optimization problems<end_working_out><SOLUTION>Proven.</SOLUTION>\n"
     ]
    }
   ],
   "source": [
    "print(generate_proof(random_question, max_tokens=2048))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A geothermal power plant has three geothermal wells (A, B, and C) with maximum sustainable capacities of A: 1000 units, B: 1500 units, and C: 2000 units. The maximum operating capacity of the power generation equipment is 3000 units. To maintain the pressure in the geothermal field, some of the used hot water or steam needs to be reinjected underground, with a reinjection ratio requirement of 40%. The unit extraction costs for each geothermal well are A: 5 units, B: 4 units, and C: 3 units, and the environmental protection cost is 2 units. Assuming the electricity market demand for a time period t is 2800 units, and each unit of electricity generation brings 1 unit of revenue.\n",
      "How should the extraction quantities of the three geothermal wells be scheduled to meet the electricity market demand while maximizing revenue and minimizing costs? Design a scheduling plan and calculate the maximum total revenue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(random_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### What We Accomplished\n",
    "- ‚úÖ Loaded 340 convex optimization exercises\n",
    "- ‚úÖ Formatted with reasoning tags\n",
    "- ‚úÖ Trained with SFT for 15 epochs (~1,000+ steps)\n",
    "- ‚úÖ Saved trained LoRA adapter\n",
    "- ‚úÖ Tested on sample problems\n",
    "\n",
    "### Model Location\n",
    "- **Final model**: `optimization_sft_model/`\n",
    "- **Checkpoints**: `outputs/optimization_sft/checkpoint-*/`\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**If format is correct but quality needs improvement:**\n",
    "1. Train for more epochs (20-30)\n",
    "2. Try a larger model: `unsloth/Qwen2.5-3B` or `unsloth/Qwen2.5-7B`\n",
    "3. Adjust learning rate (try 1e-4 or 3e-4)\n",
    "4. Increase max_seq_length to 3072 or 4096 for longer proofs\n",
    "\n",
    "**If ready for GRPO:**\n",
    "1. Use this SFT model as base\n",
    "2. Apply GRPO with optimization exercises\n",
    "3. Design reward functions for proof quality\n",
    "\n",
    "### Loading the Model Later\n",
    "\n",
    "```python\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"optimization_sft_model\",\n",
    "    max_seq_length = 2048,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
